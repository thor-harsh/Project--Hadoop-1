# Project--Hadoop-1

<table>

  **In this project we use MapReduce which is a heart of hadoop and coded it using python to find the count the total ratings of each movie id.**

  MapReduce is a programming paradigm that enables massive scalability across hundreds or thousands of servers in a Hadoop cluster.
  As the processing component, MapReduce is the heart of Apache Hadoop.
  The term "MapReduce" refers to two separate and distinct tasks that Hadoop programs perform.<br></br>
  The first is the map job, which takes a set of data and converts it into another set of data, where individual elements are broken down into tuples (key/value pairs).<br></br>

  The reduce job takes the output from a map as input and combines those data tuples into a smaller set of tuples. As the sequence of the name MapReduce implies, the reduce job is always performed after the map job.<br></br>

  **MapReduce programming offers several benefits to help you gain valuable insights from your big data:**

 **Scalability**: Businesses can process petabytes of data stored in the Hadoop Distributed File System (HDFS).<br></br>
 **Flexibility**: Hadoop enables easier access to multiple sources of data and multiple types of data.
 **Speed**: With parallel processing and minimal data movement, Hadoop offers fast processing of massive amounts of data.
 **Simple**: Developers can write code in a choice of languages, including Java, C++ and Python.

</table>
